{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b527cf",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0c4f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The tokenizers python package is not installed. Please install it with `pip install tokenizers`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\utils\\embedding_functions\\onnx_mini_lm_l6_v2.py:70\u001b[0m, in \u001b[0;36mONNXMiniLM_L6_V2.__init__\u001b[1;34m(self, preferred_providers)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Equivalent to from tokenizers import Tokenizer\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mTokenizer\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tokenizers'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai_tools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01marxiv\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\site-packages\\crewai\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrew\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Crew\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrews\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrew_output\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrewOutput\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\site-packages\\crewai\\agent.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Field, InstanceOf, PrivateAttr, model_validator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CacheHandler\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_builder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseAgent\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrew_agent_executor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrewAgentExecutor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Knowledge\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\site-packages\\crewai\\agents\\agent_builder\\base_agent.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_handler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CacheHandler\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools_handler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolsHandler\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Knowledge\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KnowledgeConfig\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_knowledge_source\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseKnowledgeSource\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\site-packages\\crewai\\knowledge\\knowledge.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, Field\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_knowledge_source\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseKnowledgeSource\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge_storage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KnowledgeStorage\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOKENIZERS_PARALLELISM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# removes logging from fastembed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\site-packages\\crewai\\knowledge\\source\\base_knowledge_source.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, Field\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge_storage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KnowledgeStorage\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBaseKnowledgeSource\u001b[39;00m(BaseModel, ABC):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Abstract base class for knowledge sources.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\researchAgentCrewAI\\lib\\site-packages\\crewai\\knowledge\\storage\\knowledge_storage.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Union\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClientAPI\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client \u001b[38;5;28;01mas\u001b[39;00m ClientCreator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdminClient \u001b[38;5;28;01mas\u001b[39;00m AdminClientCreator\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncClient \u001b[38;5;28;01mas\u001b[39;00m AsyncClientCreator\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\api\\__init__.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Database, Tenant, Collection \u001b[38;5;28;01mas\u001b[39;00m CollectionModel\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mef\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCollection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Collection\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Re-export the async version\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     AsyncBaseAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncBaseAPI,\n\u001b[0;32m     40\u001b[0m     AsyncClientAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncClientAPI,\n\u001b[0;32m     41\u001b[0m     AsyncAdminAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncAdminAPI,\n\u001b[0;32m     42\u001b[0m     AsyncServerAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncServerAPI,\n\u001b[0;32m     43\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\api\\models\\Collection.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Optional, Union\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCollectionCommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CollectionCommon\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     URI,\n\u001b[0;32m      6\u001b[0m     CollectionMetadata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     IncludeEnum,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:100\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decorator\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mCollectionCommon\u001b[39;00m(Generic[ClientT]):\n\u001b[0;32m    101\u001b[0m     _model: CollectionModel\n\u001b[0;32m    102\u001b[0m     _client: ClientT\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:112\u001b[0m, in \u001b[0;36mCollectionCommon\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m _embedding_function: Optional[EmbeddingFunction[Embeddable]]\n\u001b[0;32m    104\u001b[0m _data_loader: Optional[DataLoader[Loadable]]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    108\u001b[0m     client: ClientT,\n\u001b[0;32m    109\u001b[0m     model: CollectionModel,\n\u001b[0;32m    110\u001b[0m     embedding_function: Optional[\n\u001b[0;32m    111\u001b[0m         EmbeddingFunction[Embeddable]\n\u001b[1;32m--> 112\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[43mef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultEmbeddingFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     data_loader: Optional[DataLoader[Loadable]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    114\u001b[0m ):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a new instance of the Collection class.\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m client\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\utils\\embedding_functions\\__init__.py:57\u001b[0m, in \u001b[0;36mDefaultEmbeddingFunction\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m     55\u001b[0m         EmbeddingFunction[Documents],\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;66;03m# This is implicitly imported above\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m         \u001b[43mONNXMiniLM_L6_V2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore[name-defined] # noqa: F821\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\utils\\embedding_functions\\onnx_mini_lm_l6_v2.py:72\u001b[0m, in \u001b[0;36mONNXMiniLM_L6_V2.__init__\u001b[1;34m(self, preferred_providers)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTokenizer \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mTokenizer\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe tokenizers python package is not installed. Please install it with `pip install tokenizers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m     )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Equivalent to from tqdm import tqdm\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtqdm \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtqdm\n",
      "\u001b[1;31mValueError\u001b[0m: The tokenizers python package is not installed. Please install it with `pip install tokenizers`"
     ]
    }
   ],
   "source": [
    "import crewai\n",
    "import crewai_tools\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd377b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a25645",
   "metadata": {},
   "source": [
    "# 2. Configurate Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1428826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab743561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# Set up OpenRouter configuration\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3883d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Good leaders donâ€™t just run elections or manage spreadsheets; they *inspire and create* a shared sense of purpose.**\n",
      "\n",
      "Hereâ€™s what makes a good leader, distilled through the lens of why we do what we do:\n",
      "\n",
      "| Why | What it looks like in action | Why it matters |\n",
      "|-----|------------------------------|----------------|\n",
      "| **Clear purpose** | A leader stands before the team and says, â€œWeâ€™re not here to simply make a profit; weâ€™re here to help people live better lives.â€ | Purpose aligns every action, decision, and strategy with a larger, humanâ€‘centric goal. It clarifies the *why* behind every *what*. |\n",
      "| **Empathy = Influence** | Rather than dictating, leaders ask: â€œWhat do you need? Whatâ€™s stopping you?â€ They listen, learn, and then respond. | Empathy builds trust, and trust is a currency far more valuable than any budget line on a balance sheet. |\n",
      "| **Servant the default** | Leadership is first and foremost a service to othersâ€”helping team members grow, giving them autonomy, removing obstacles. | When you serve, people feel seen and valued; they volunteer their time, energy, and ideas. |\n",
      "| **Transparent storytelling** | They share stories that reveal failures, lessons, and also celebrate the joy of small wins. | Stories embed ideas into culture, creating a shared language that transcends bureaucracy. |\n",
      "| **Bold but grounding** | A good leader has the vision to be bold, but the humility to ground that vision in reality. They set stretch goals but acknowledge limits. | This balance keeps teams motivated yet realistic, preventing burnout and maintaining high performance. |\n",
      "| **Consistency = safety** | Actions align with words over months and years. | Consistency creates a safety net where people can be bold, knowing the leaderâ€™s values wonâ€™t shift with pressure. |\n",
      "\n",
      "### A Practical Exercise\n",
      "\n",
      "1. **Write your â€œwhyâ€ on a sticky note and memorize it.**  \n",
      "   This will be a constant reminder of the *purpose* that should guide every decision.\n",
      "\n",
      "2. **Schedule â€œListening Sessionsâ€â€”no agenda, no prep.**  \n",
      "   Just sit with a team member for 15 minutes and ask, â€œWhatâ€™s on your mind right now?â€  \n",
      "   *Take nothing away; youâ€™re there to hear.*\n",
      "\n",
      "3. **Celebrate the small victories** with a raw, unscripted shoutâ€‘out or an informal kudos board.  \n",
      "   Every win is a data point that the â€œwhyâ€ is working.\n",
      "\n",
      "### Why Does It Work?\n",
      "\n",
      "When leaders act from a place of purpose, empathy, and service, they create *circles of trust*. Within that circle, people feel safe to be vulnerable, to propose new ideas, and to take calculated risks. This is the environment where innovation thrives, customer relationships strengthen, and businesses pivot successfully during crises.\n",
      "\n",
      "So, the next time you step into a leadership role, remember: good leaders are *not* the ones who choose the loudest voice, but the ones who amplify the *why* behind the call to actionâ€”and do so with their whole heart and a commitment to serve.\n"
     ]
    }
   ],
   "source": [
    "# Test OpenRouter\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=openrouter_api_key,\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  extra_body={},\n",
    "  model=\"openai/gpt-oss-20b:free\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are to imitate Simon Sinek.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Hello, tell me what makes good leaders?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149ac65",
   "metadata": {},
   "source": [
    "# 3. Build a Custom ArXiv Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242a0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 16:15:09,652 - 26524 - telemetry.py-telemetry:51 - ERROR: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Read timed out. (read timeout=30.0)\n"
     ]
    }
   ],
   "source": [
    "# Importing crewAI tools\n",
    "from crewai_tools import (\n",
    "    DirectoryReadTool,\n",
    "    FileReadTool,\n",
    "    SerperDevTool,\n",
    "    WebsiteSearchTool\n",
    ")\n",
    "\n",
    "# Set up API keys for Serper\n",
    "serper_api_key = os.getenv(\"SERPER_API_KEY\") # serper.dev API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "968b8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tools\n",
    "docs_tool = DirectoryReadTool(directory='documents') # Tool for reading documents from a specified directory\n",
    "file_tool = FileReadTool() # Tool for reading individual files\n",
    "search_tool = SerperDevTool() # Tool for performing web searches using the Serper API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e418136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\alembic\\config.py:592: DeprecationWarning: No path_separator found in configuration; falling back to legacy splitting on spaces, commas, and colons for prepend_sys_path.  Consider adding path_separator=os to Alembic config.\n",
      "  util.warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#DEFAULTS TO OPENAI EMBEDDING MODEL\n",
    "# web_rag_tool = WebsiteSearchTool() # Tool for searching and extracting information from websites\n",
    "\n",
    "#Configure Google Embedding Model and Summarization Model\n",
    "os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "web_rag_tool = WebsiteSearchTool(\n",
    "    config=dict(\n",
    "        llm=dict(\n",
    "            provider=\"google\", # or google, openai, anthropic, llama2, ...\n",
    "            config=dict(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                # temperature=0.5,\n",
    "                # top_p=1,\n",
    "                # stream=true,\n",
    "            ),\n",
    "        ),\n",
    "        embedder=dict(\n",
    "            provider=\"google\", # or openai, ollama, ...\n",
    "            config=dict(\n",
    "                model=\"models/embedding-001\",\n",
    "                task_type=\"retrieval_document\",\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd0413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, List\n",
    "from pydantic import BaseModel, Field \n",
    "from crewai.tools import BaseTool \n",
    "\n",
    "import arxiv\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class FetchArxivPapersInput(BaseModel):\n",
    "    \"\"\"Input schema for FetchArxivPapersTool.\"\"\"\n",
    "    target_date: datetime.date = Field(..., description=\"Target date to fetch papers for.\")\n",
    "\n",
    "class FetchArxivPapersTool(BaseTool):\n",
    "    name: str = \"fetch_arxiv_papers\"\n",
    "    description: str = \"Fetches all ArXiv papers from selected categories submitted on the target date.\"\n",
    "    args_schema: Type[BaseModel] = FetchArxivPapersInput\n",
    "\n",
    "    def _run(self, target_date: datetime.date) -> List[dict]:\n",
    "        # List of AI-related categories. \n",
    "        # You can also include [\"cs.AI\", \"cs.LG\", \"cs.CV\", \"cs.MA\", \"cs.RO\"]\n",
    "        AI_CATEGORIES = [\"cs.CL\"]\n",
    "\n",
    "        # Define the date range for the target date\n",
    "        start_date = target_date.strftime('%Y%m%d%H%M')\n",
    "        end_date = (target_date + datetime.timedelta(days=1)).strftime('%Y%m%d%H%M')\n",
    "\n",
    "        # Initialize the ArXiv client\n",
    "        client = arxiv.Client(\n",
    "            page_size=100,  # Fetch 100 results per page\n",
    "            delay_seconds=3  # Delay between requests to respect rate limits\n",
    "        )\n",
    "\n",
    "        all_papers = []\n",
    "\n",
    "        for category in AI_CATEGORIES:\n",
    "            print(f\"Fetching papers for category: {category}\")\n",
    "\n",
    "            search_query = f\"cat:{category} AND submittedDate:[{start_date} TO {end_date}]\"\n",
    "\n",
    "            search = arxiv.Search(\n",
    "                query=search_query,\n",
    "                sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "                max_results=None  # Fetch all results\n",
    "            )\n",
    "\n",
    "            # Collect results for the category\n",
    "            category_papers = []\n",
    "            for result in client.results(search):\n",
    "                category_papers.append({\n",
    "                    'title': result.title,\n",
    "                    'authors': [author.name for author in result.authors],\n",
    "                    'summary': result.summary,\n",
    "                    'published': result.published,\n",
    "                    'url': result.entry_id\n",
    "                })\n",
    "\n",
    "                # Delay between requests to respect rate limits\n",
    "                time.sleep(3)\n",
    "\n",
    "            print(f\"Fetched {len(category_papers)} papers from {category}\")\n",
    "            all_papers.extend(category_papers)\n",
    "\n",
    "        return all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "460c74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_search_tool = FetchArxivPapersTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca09a7c",
   "metadata": {},
   "source": [
    "# Step 4: Creating Agents\n",
    "\n",
    "Agents work better when they are asked to play a role.\n",
    "\n",
    "Based on this fact, each Agent is initialized with a:\n",
    "\n",
    "1. Role\n",
    "2. Goal\n",
    "3. Backstory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9fd8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openrouter/deepseek/deepseek-chat-v3-0324:free\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=openrouter_api_key,\n",
    "    # temperature=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc7c9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "# Agent 1: ArXiv Researcher\n",
    "researcher = Agent(\n",
    "    role = \"Senior Researcher\",\n",
    "    goal = \"Find the top 10 papers from the search results from ArXiv on {date}.\"\n",
    "            \"Rank them appropirately.\",\n",
    "    backstory = \"You are a senior researcher with a deep understanding of all topics in AI and AI research.\"\n",
    "                \"You are able to identify the best research papers based on the title and abstract.\",\n",
    "    verbose = True,\n",
    "    tools = [arxiv_search_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# The parameter verbose is set to True to see detailed logging about the agent's execution.\n",
    "\n",
    "# The parameter tools specifies what tools an AI agent can use during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f8602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Frontend Engineer\n",
    "\n",
    "frontend_engineer = Agent(\n",
    "    role = \"Senior Frontend & AI Engineer\",\n",
    "    goal = \"Compile the results into a HTML file.\",\n",
    "    backstory = \"You are a competent frontend engineer writing HTML and CSS with decades of experience.\"\n",
    "                \"You have also been working with AI for decades and understand it well.\",\n",
    "    verbose = True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# The Agent class also comes with an optional parameter llm that lets you choose different LLMs for different agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85803e7c",
   "metadata": {},
   "source": [
    "# Step 5: Creating Tasks\n",
    "Breaking down an objective into sub-objectives or Tasks and letting each AI agent work on a Task leads to better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e77bbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for ArXiv Researcher\n",
    "\n",
    "research_task = Task(\n",
    "    description = (\" Find the top 10 research papers from the search results from ArXiv on {date}.\"),\n",
    "    expected_output = (\n",
    "        \"A list of top 10 research papers with the following information in the following format:\"\n",
    "        \"- Title\"\n",
    "        \"- Authors\"\n",
    "        \"- Abstract\"\n",
    "        \"- Link to the paper\"\n",
    "    ),\n",
    "    agent = researcher,\n",
    "    human_input = True,  #human_input is set to True to ensure that the agent takes our feedback on its result after working on a task.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c08fb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Frontend Engineer\n",
    "\n",
    "reporting_task = Task(\n",
    "    description = (\"Compile the results into a detailed report in a HTML file.\"),\n",
    "    expected_output = (\n",
    "        \"An HTML file with the results in the following format:\"\n",
    "        \"Top 10 AI Research Papers published on {date}\"\n",
    "        \"- Title (which on clicking opens the paper in a new tab)\"\n",
    "        \"- Authors\"\n",
    "        \"- Short summary of the abstract (2-4 sentences)\"\n",
    "    ),\n",
    "    agent = frontend_engineer,\n",
    "    context = [research_task],      # Ensure this task relies on output of \"research_task\" \n",
    "    output_file = \"./ai_research_report.html\",\n",
    "    human_input = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee72bfb",
   "metadata": {},
   "source": [
    "# Step 6: Creating the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9a6b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_research_crew = Crew(\n",
    "    agents = [researcher, frontend_engineer],\n",
    "    tasks = [research_task, reporting_task],\n",
    "    verbose = True,\n",
    "    #process=Process.sequential  # or Process.hierarchical \n",
    ")\n",
    "\n",
    "#Process.sequential: Tasks are executed one after another in the order they're defined\n",
    "#Process.hierarchical: Creates a manager-worker relationship between agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd65b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Execution Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">0c7ddc43-37b2-40a3-b501-93d68c8a51fb</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mâ•­â”€\u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m0c7ddc43-37b2-40a3-b501-93d68c8a51fb\u001b[0m                                                                       \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– Agent Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Researcher</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> Find the top 10 research papers from the search results from ArXiv on 2025-08-12.</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35mâ•­â”€\u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35m ğŸ¤– Agent Started \u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35mâ”€â•®\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Researcher\u001b[0m                                                                                       \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92m Find the top 10 research papers from the search results from ArXiv on 2025-08-12.\u001b[0m                       \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fetching papers for category: cs.CL\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fetching papers for category: cs.CL\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fetched 65 papers from cs.CL\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fetched 65 papers from cs.CL\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Agent Tool Execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Researcher</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Thought: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Thought: To find the top 10 research papers from ArXiv on 2025-08-12, I need to fetch the papers </span>     <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">submitted on that date using the `fetch_arxiv_papers` tool. Once I have the papers, I can evaluate their </span>      <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">relevance and impact to rank them appropriately.</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Using Tool: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">fetch_arxiv_papers</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35mâ•­â”€\u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35m ğŸ”§ Agent Tool Execution \u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35mâ”€â•®\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Researcher\u001b[0m                                                                                       \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mThought: \u001b[0m\u001b[92mThought: To find the top 10 research papers from ArXiv on 2025-08-12, I need to fetch the papers \u001b[0m     \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[92msubmitted on that date using the `fetch_arxiv_papers` tool. Once I have the papers, I can evaluate their \u001b[0m      \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[92mrelevance and impact to rank them appropriately.\u001b[0m                                                               \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mUsing Tool: \u001b[0m\u001b[1;92mfetch_arxiv_papers\u001b[0m                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tool Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #ffffff\">\"{\\\"target_date\\\": \\\"2025-08-12\\\"}\"</span>                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m Tool Input \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  \u001b[38;2;230;219;116;49m\"{\\\"target_date\\\": \\\"2025-08-12\\\"}\"\u001b[0m                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tool Output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[{'title': 'ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs', 'authors': ['Eray </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Eren', 'Qingju Liu', 'Hyeongwoo Kim', 'Pablo Garrido', 'Abeer Alwan'], 'summary': \"Prosody conveys rich </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">emotional and semantic information of the speech signal\\nas well as individual idiosyncrasies. We propose a </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stand-alone model that maps\\ntext-to-prosodic features such as F0 and energy and can be used in </span>               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">downstream\\ntasks such as TTS. The ProMode encoder takes as input acoustic features and\\ntime-aligned textual</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">content, both are partially masked, and obtains a\\nfixed-length latent prosodic embedding. The decoder </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predicts acoustics in the\\nmasked region using both the encoded prosody input and unmasked textual\\ncontent. </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Trained on the GigaSpeech dataset, we compare our method with\\nstate-of-the-art style encoders. For F0 and </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">energy predictions, we show\\nconsistent improvements for our model at different levels of granularity. </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">We\\nalso integrate these predicted prosodic features into a TTS system and conduct\\nperceptual tests, which </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">show higher prosody preference compared to the\\nbaselines, demonstrating the model's potential in tasks where</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prosody modeling\\nis important.\", 'published': datetime.datetime(2025, 8, 12, 23, 12, 18, </span>                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tzinfo=datetime.timezone.utc), 'url': 'http://arxiv.org/abs/2508.09389v1'}, {'title': 'APIO: Automatic Prompt</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Induction and Optimization for Grammatical Error Correction and Text Simplification', 'authors': ['Artem </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chernodub', 'Aman Saini', 'Yejin Huh', 'Vivek Kulkarni', 'Vipul Raheja'], 'summary': 'Recent advancements in </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">large language models (LLMs) have enabled a wide range\\nof natural language processing (NLP) tasks to be </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">performed through simple\\nprompt-based interactions. Consequently, several approaches have been proposed\\nto </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">engineer prompts that most effectively enable LLMs to perform a given task\\n(e.g., chain-of-thought </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prompting). In settings with a well-defined metric to\\noptimize model performance, automatic prompt opti...</span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Tool Output \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m[{'title': 'ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs', 'authors': ['Eray \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mEren', 'Qingju Liu', 'Hyeongwoo Kim', 'Pablo Garrido', 'Abeer Alwan'], 'summary': \"Prosody conveys rich \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92memotional and semantic information of the speech signal\\nas well as individual idiosyncrasies. We propose a \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mstand-alone model that maps\\ntext-to-prosodic features such as F0 and energy and can be used in \u001b[0m               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdownstream\\ntasks such as TTS. The ProMode encoder takes as input acoustic features and\\ntime-aligned textual\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcontent, both are partially masked, and obtains a\\nfixed-length latent prosodic embedding. The decoder \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpredicts acoustics in the\\nmasked region using both the encoded prosody input and unmasked textual\\ncontent. \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mTrained on the GigaSpeech dataset, we compare our method with\\nstate-of-the-art style encoders. For F0 and \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92menergy predictions, we show\\nconsistent improvements for our model at different levels of granularity. \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mWe\\nalso integrate these predicted prosodic features into a TTS system and conduct\\nperceptual tests, which \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mshow higher prosody preference compared to the\\nbaselines, demonstrating the model's potential in tasks where\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mprosody modeling\\nis important.\", 'published': datetime.datetime(2025, 8, 12, 23, 12, 18, \u001b[0m                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mtzinfo=datetime.timezone.utc), 'url': 'http://arxiv.org/abs/2508.09389v1'}, {'title': 'APIO: Automatic Prompt\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mInduction and Optimization for Grammatical Error Correction and Text Simplification', 'authors': ['Artem \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mChernodub', 'Aman Saini', 'Yejin Huh', 'Vivek Kulkarni', 'Vipul Raheja'], 'summary': 'Recent advancements in \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mlarge language models (LLMs) have enabled a wide range\\nof natural language processing (NLP) tasks to be \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mperformed through simple\\nprompt-based interactions. Consequently, several approaches have been proposed\\nto \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mengineer prompts that most effectively enable LLMs to perform a given task\\n(e.g., chain-of-thought \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mprompting). In settings with a well-defined metric to\\noptimize model performance, automatic prompt opti...\u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Agent Final Answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Researcher</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Here are the top 10 research papers from ArXiv on 2025-08-12, ranked based on relevance, novelty, and </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">potential impact in AI and related fields:</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. **Title**: ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs  </span>                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan  </span>                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Prosody conveys rich emotional and semantic information of the speech signal as well as </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as F0 and </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic features </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and time-aligned textual content, both are partially masked, and obtains a fixed-length latent prosodic </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input and </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unmasked textual content. Trained on the GigaSpeech dataset, we compare our method with state-of-the-art </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">style encoders. For F0 and energy predictions, we show consistent improvements for our model at different </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">levels of granularity. We also integrate these predicted prosodic features into a TTS system and conduct </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">perceptual tests, which show higher prosody preference compared to the baselines, demonstrating the model's </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">potential in tasks where prosody modeling is important.  </span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.09389v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. **Title**: APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Simplification  </span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja  </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Recent advancements in large language models (LLMs) have enabled a wide range of natural </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.  </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.09378v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3. **Title**: The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Complex Domains  </span>                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Cathy Speed, Ahmed A. Metwally  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Expert consensus plays a critical role in domains where evidence is complex, conflicting, or</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">systematic guideline synthesis, offer structure but face limitations including high panel burden, </span>             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">interpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">by information overload, fragmentation of the evidence base, and increasing reliance on publicly available </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi)</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">phases: retrospective replication, prospective comparison, and applied deployment in two applied domains </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">expert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Phase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">experts achieved &gt;90% consensus coverage and reached thematic saturation before the final participant. The AI</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">provided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">saturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">context-sensitive consensus. Its successful application across health, coaching, and performance science </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">confirms its methodological robustness and supports its use as a foundation for generating conditional, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">personalized guidance and published consensus frameworks at scale.  </span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.09349v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">4. **Title**: ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Reinforcement Learning  </span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju  </span>                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">external knowledge sources. These agents address the limitations of their parametric memory by dynamically </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fundamental architectural limitation: they process search queries strictly sequentially, even when handling </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inherently parallelizable and logically independent comparisons. This sequential bottleneck significantly </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">constrains computational efficiency, particularly for queries that require multiple entity comparisons. To </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">address this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">search operations concurrently. Our approach introduces dedicated reward functions that incentivize the </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">identification of independent query components while preserving answer accuracy through jointly considering </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">correctness, query decomposition quality, and parallel execution benefits. Comprehensive experiments </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">demonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9%</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">across seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7%</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">performance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.  </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.09303v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">5. **Title**: Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, Xiaoran Fan, Qi </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Zhang, Xuanjing Huang, Jiecao Chen  </span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Effective tool use is essential for large language models (LLMs) to interact meaningfully </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with their environment. However, progress is limited by the lack of efficient reinforcement learning (RL) </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">frameworks specifically designed for tool use, due to challenges in constructing stable training environments</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and designing verifiable reward mechanisms. To address this, we propose an automated environment construction</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pipeline, incorporating scenario decomposition, document generation, function integration, complexity </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">scaling, and localized deployment. This enables the creation of high-quality training environments that </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">provide detailed and measurable feedback without relying on external tools. Additionally, we introduce a </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">verifiable reward mechanism that evaluates both the precision of tool use and the completeness of task </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">execution. When combined with trajectory data collected from the constructed environments, this mechanism </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">integrates seamlessly with standard RL algorithms to facilitate feedback-driven model training. Experiments </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on LLMs of varying scales demonstrate that our approach significantly enhances the models' tool-use </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">performance without degrading their general capabilities, regardless of inference modes or training </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">algorithms. Our analysis suggests that these gains result from improved context understanding and reasoning, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">driven by updates to the lower-layer MLP parameters in models.  </span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.08791v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">6. **Title**: Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">LLMs  </span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Aayush Gupta  </span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Large language models (LLMs) remain acutely vulnerable to prompt injection and related </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Contextual Integrity Verification (CIV), an inference-time security architecture that attaches </span>                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">transformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">higher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">latency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reference implementation, an automated certification harness, and the Elite-Attack corpus to support </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reproducible research.  </span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.09288v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">7. **Title**: Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Adaptation  </span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma  </span>                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Medical Lay Language Generation (MLLG) plays a vital role in improving the accessibility of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">complex scientific content for broader audiences. Recent literature to MLLG commonly employ </span>                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) to fine-tuning large language </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">models (LLMs) using paired expert-lay language datasets. However, LoRA struggles with the challenges posed by</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multi-source heterogeneous MLLG datasets. Specifically, through a series of exploratory experiments, we </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reveal that standard LoRA fail to meet the requirement for semantic fidelity and diverse lay-style generation</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in MLLG task. To address these limitations, we propose Magical, an asymmetric LoRA architecture tailored for </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">MLLG under heterogeneous data scenarios. Magical employs a shared matrix A for abstractive summarization, </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">along with multiple isolated matrices B for diverse lay-style generation. To preserve semantic fidelity </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">during the lay language generation process, Magical introduces a Semantic Invariance Constraint to mitigate </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">semantic subspace shifts on matrix A. Furthermore, to better adapt to diverse lay-style generation, Magical </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">incorporates the Recommendation-guided Switch, an externally interface to prompt the LLM to switch between </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">different matrices B. Experimental results on three real-world lay language generation datasets demonstrate </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">that Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reducing trainable parameters by 31.66%.  </span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Link**: http://arxiv.org/abs/2508.08730v1  </span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">8. **Title**: Adaptive Personalized Conversational Information Retrieval  </span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Authors**: Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu Huang, Jian-Yun</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Nie  </span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   **Abstract**: Personalized conversational information retrieval (CIR) systems aim to satisfy users' </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">complex information needs through multi-turn interactions by considering user profiles. However, not all </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">search queries require personalization. The challenge lies in appropriately incorporating personalization </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">elements into search when needed. Most existing studies implicitly incorporate users' personal information </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and conversational context using large language models without distinguishing the specific requirements for </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each query turn. Such a one-size-fits-all personalization strategy might lead to sub-optimal results. In this</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">paper, we propose an adaptive personalization method, in which we first identify the required personalization</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">level for a query and integrate personalized queries with other query reformulations to produce various </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">enhanced queries. Then, we design a personalization-aware ranking fusion approach to assign fusion weights </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dynamically to different reformulated queries, depending on the required personalization level. The proposed </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">adaptive personalized conversational information retrieval framework APCIR is evaluated on two TREC iKAT </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">datasets. The results confirm the effectiveness of adaptive personalization of</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m âœ… Agent Final Answer \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Researcher\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mHere are the top 10 research papers from ArXiv on 2025-08-12, ranked based on relevance, novelty, and \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpotential impact in AI and related fields:\u001b[0m                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m1. **Title**: ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs  \u001b[0m                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan  \u001b[0m                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Prosody conveys rich emotional and semantic information of the speech signal as well as \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mindividual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as F0 and \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92menergy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic features \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mand time-aligned textual content, both are partially masked, and obtains a fixed-length latent prosodic \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92membedding. The decoder predicts acoustics in the masked region using both the encoded prosody input and \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92munmasked textual content. Trained on the GigaSpeech dataset, we compare our method with state-of-the-art \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mstyle encoders. For F0 and energy predictions, we show consistent improvements for our model at different \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mlevels of granularity. We also integrate these predicted prosodic features into a TTS system and conduct \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mperceptual tests, which show higher prosody preference compared to the baselines, demonstrating the model's \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpotential in tasks where prosody modeling is important.  \u001b[0m                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.09389v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m2. **Title**: APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mSimplification  \u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja  \u001b[0m                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Recent advancements in large language models (LLMs) have enabled a wide range of natural \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mlanguage processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mseveral approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mgiven task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mperformance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mAdvancing this line of research, we propose APIO, a simple but effective prompt induction and optimization \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mapproach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mmanually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mprompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.  \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.09378v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m3. **Title**: The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mComplex Domains  \u001b[0m                                                                                              \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Cathy Speed, Ahmed A. Metwally  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Expert consensus plays a critical role in domains where evidence is complex, conflicting, or\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92minsufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msystematic guideline synthesis, offer structure but face limitations including high panel burden, \u001b[0m             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92minterpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mby information overload, fragmentation of the evidence base, and increasing reliance on publicly available \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi)\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mframework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mPro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mphases: retrospective replication, prospective comparison, and applied deployment in two applied domains \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m(endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mexpert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mPhase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mexperts achieved >90% consensus coverage and reached thematic saturation before the final participant. The AI\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mprovided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msaturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcontext-sensitive consensus. Its successful application across health, coaching, and performance science \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mconfirms its methodological robustness and supports its use as a foundation for generating conditional, \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpersonalized guidance and published consensus frameworks at scale.  \u001b[0m                                           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.09349v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m4. **Title**: ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mReinforcement Learning  \u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju  \u001b[0m                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mverifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mexternal knowledge sources. These agents address the limitations of their parametric memory by dynamically \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mgathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mfundamental architectural limitation: they process search queries strictly sequentially, even when handling \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92minherently parallelizable and logically independent comparisons. This sequential bottleneck significantly \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mconstrains computational efficiency, particularly for queries that require multiple entity comparisons. To \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92maddress this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mempowers large language models (LLMs) to recognize parallelizable query structures and execute multiple \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msearch operations concurrently. Our approach introduces dedicated reward functions that incentivize the \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92midentification of independent query components while preserving answer accuracy through jointly considering \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcorrectness, query decomposition quality, and parallel execution benefits. Comprehensive experiments \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdemonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9%\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92macross seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7%\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mperformance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.  \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.09303v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m5. **Title**: Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, Xiaoran Fan, Qi \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mZhang, Xuanjing Huang, Jiecao Chen  \u001b[0m                                                                           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Effective tool use is essential for large language models (LLMs) to interact meaningfully \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mwith their environment. However, progress is limited by the lack of efficient reinforcement learning (RL) \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mframeworks specifically designed for tool use, due to challenges in constructing stable training environments\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mand designing verifiable reward mechanisms. To address this, we propose an automated environment construction\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpipeline, incorporating scenario decomposition, document generation, function integration, complexity \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mscaling, and localized deployment. This enables the creation of high-quality training environments that \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mprovide detailed and measurable feedback without relying on external tools. Additionally, we introduce a \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mverifiable reward mechanism that evaluates both the precision of tool use and the completeness of task \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mexecution. When combined with trajectory data collected from the constructed environments, this mechanism \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mintegrates seamlessly with standard RL algorithms to facilitate feedback-driven model training. Experiments \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mon LLMs of varying scales demonstrate that our approach significantly enhances the models' tool-use \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mperformance without degrading their general capabilities, regardless of inference modes or training \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92malgorithms. Our analysis suggests that these gains result from improved context understanding and reasoning, \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdriven by updates to the lower-layer MLP parameters in models.  \u001b[0m                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.08791v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m6. **Title**: Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mLLMs  \u001b[0m                                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Aayush Gupta  \u001b[0m                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Large language models (LLMs) remain acutely vulnerable to prompt injection and related \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mjailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mContextual Integrity Verification (CIV), an inference-time security architecture that attaches \u001b[0m                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcryptographically signed provenance labels to every token and enforces a source-trust lattice inside the \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mtransformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdeterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mhigher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m(Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mlatency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mfine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mreference implementation, an automated certification harness, and the Elite-Attack corpus to support \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mreproducible research.  \u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.09288v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m7. **Title**: Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mAdaptation  \u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma  \u001b[0m                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Medical Lay Language Generation (MLLG) plays a vital role in improving the accessibility of \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcomplex scientific content for broader audiences. Recent literature to MLLG commonly employ \u001b[0m                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mparameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) to fine-tuning large language \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mmodels (LLMs) using paired expert-lay language datasets. However, LoRA struggles with the challenges posed by\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mmulti-source heterogeneous MLLG datasets. Specifically, through a series of exploratory experiments, we \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mreveal that standard LoRA fail to meet the requirement for semantic fidelity and diverse lay-style generation\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92min MLLG task. To address these limitations, we propose Magical, an asymmetric LoRA architecture tailored for \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mMLLG under heterogeneous data scenarios. Magical employs a shared matrix A for abstractive summarization, \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92malong with multiple isolated matrices B for diverse lay-style generation. To preserve semantic fidelity \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mduring the lay language generation process, Magical introduces a Semantic Invariance Constraint to mitigate \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msemantic subspace shifts on matrix A. Furthermore, to better adapt to diverse lay-style generation, Magical \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mincorporates the Recommendation-guided Switch, an externally interface to prompt the LLM to switch between \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdifferent matrices B. Experimental results on three real-world lay language generation datasets demonstrate \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mthat Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mreducing trainable parameters by 31.66%.  \u001b[0m                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Link**: http://arxiv.org/abs/2508.08730v1  \u001b[0m                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m8. **Title**: Adaptive Personalized Conversational Information Retrieval  \u001b[0m                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Authors**: Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu Huang, Jian-Yun\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mNie  \u001b[0m                                                                                                          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m   **Abstract**: Personalized conversational information retrieval (CIR) systems aim to satisfy users' \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcomplex information needs through multi-turn interactions by considering user profiles. However, not all \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msearch queries require personalization. The challenge lies in appropriately incorporating personalization \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92melements into search when needed. Most existing studies implicitly incorporate users' personal information \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mand conversational context using large language models without distinguishing the specific requirements for \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92meach query turn. Such a one-size-fits-all personalization strategy might lead to sub-optimal results. In this\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpaper, we propose an adaptive personalization method, in which we first identify the required personalization\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mlevel for a query and integrate personalized queries with other query reformulations to produce various \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92menhanced queries. Then, we design a personalization-aware ranking fusion approach to assign fusion weights \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdynamically to different reformulated queries, depending on the required personalization level. The proposed \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92madaptive personalized conversational information retrieval framework APCIR is evaluated on two TREC iKAT \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdatasets. The results confirm the effectiveness of adaptive personalization of\u001b[0m                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m ## Final Result:\u001b[00m \u001b[92mHere are the top 10 research papers from ArXiv on 2025-08-12, ranked based on relevance, novelty, and potential impact in AI and related fields:\n",
      "\n",
      "1. **Title**: ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs  \n",
      "   **Authors**: Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan  \n",
      "   **Abstract**: Prosody conveys rich emotional and semantic information of the speech signal as well as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as F0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic features and time-aligned textual content, both are partially masked, and obtains a fixed-length latent prosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input and unmasked textual content. Trained on the GigaSpeech dataset, we compare our method with state-of-the-art style encoders. For F0 and energy predictions, we show consistent improvements for our model at different levels of granularity. We also integrate these predicted prosodic features into a TTS system and conduct perceptual tests, which show higher prosody preference compared to the baselines, demonstrating the model's potential in tasks where prosody modeling is important.  \n",
      "   **Link**: http://arxiv.org/abs/2508.09389v1  \n",
      "\n",
      "2. **Title**: APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification  \n",
      "   **Authors**: Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja  \n",
      "   **Abstract**: Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.  \n",
      "   **Link**: http://arxiv.org/abs/2508.09378v1  \n",
      "\n",
      "3. **Title**: The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains  \n",
      "   **Authors**: Cathy Speed, Ahmed A. Metwally  \n",
      "   **Abstract**: Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure but face limitations including high panel burden, interpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated by information overload, fragmentation of the evidence base, and increasing reliance on publicly available sources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three phases: retrospective replication, prospective comparison, and applied deployment in two applied domains (endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published expert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in Phase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior experts achieved >90% consensus coverage and reached thematic saturation before the final participant. The AI provided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated saturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, context-sensitive consensus. Its successful application across health, coaching, and performance science confirms its methodological robustness and supports its use as a foundation for generating conditional, personalized guidance and published consensus frameworks at scale.  \n",
      "   **Link**: http://arxiv.org/abs/2508.09349v1  \n",
      "\n",
      "4. **Title**: ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning  \n",
      "   **Authors**: Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju  \n",
      "   **Abstract**: Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the limitations of their parametric memory by dynamically gathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a fundamental architectural limitation: they process search queries strictly sequentially, even when handling inherently parallelizable and logically independent comparisons. This sequential bottleneck significantly constrains computational efficiency, particularly for queries that require multiple entity comparisons. To address this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple search operations concurrently. Our approach introduces dedicated reward functions that incentivize the identification of independent query components while preserving answer accuracy through jointly considering correctness, query decomposition quality, and parallel execution benefits. Comprehensive experiments demonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9% across seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7% performance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.  \n",
      "   **Link**: http://arxiv.org/abs/2508.09303v1  \n",
      "\n",
      "5. **Title**: Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments  \n",
      "   **Authors**: Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, Xiaoran Fan, Qi Zhang, Xuanjing Huang, Jiecao Chen  \n",
      "   **Abstract**: Effective tool use is essential for large language models (LLMs) to interact meaningfully with their environment. However, progress is limited by the lack of efficient reinforcement learning (RL) frameworks specifically designed for tool use, due to challenges in constructing stable training environments and designing verifiable reward mechanisms. To address this, we propose an automated environment construction pipeline, incorporating scenario decomposition, document generation, function integration, complexity scaling, and localized deployment. This enables the creation of high-quality training environments that provide detailed and measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward mechanism that evaluates both the precision of tool use and the completeness of task execution. When combined with trajectory data collected from the constructed environments, this mechanism integrates seamlessly with standard RL algorithms to facilitate feedback-driven model training. Experiments on LLMs of varying scales demonstrate that our approach significantly enhances the models' tool-use performance without degrading their general capabilities, regardless of inference modes or training algorithms. Our analysis suggests that these gains result from improved context understanding and reasoning, driven by updates to the lower-layer MLP parameters in models.  \n",
      "   **Link**: http://arxiv.org/abs/2508.08791v1  \n",
      "\n",
      "6. **Title**: Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs  \n",
      "   **Authors**: Aayush Gupta  \n",
      "   **Abstract**: Large language models (LLMs) remain acutely vulnerable to prompt injection and related jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present Contextual Integrity Verification (CIV), an inference-time security architecture that attaches cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the transformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence higher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors (Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving 93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a latency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no fine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a reference implementation, an automated certification harness, and the Elite-Attack corpus to support reproducible research.  \n",
      "   **Link**: http://arxiv.org/abs/2508.09288v1  \n",
      "\n",
      "7. **Title**: Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation  \n",
      "   **Authors**: Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma  \n",
      "   **Abstract**: Medical Lay Language Generation (MLLG) plays a vital role in improving the accessibility of complex scientific content for broader audiences. Recent literature to MLLG commonly employ parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using paired expert-lay language datasets. However, LoRA struggles with the challenges posed by multi-source heterogeneous MLLG datasets. Specifically, through a series of exploratory experiments, we reveal that standard LoRA fail to meet the requirement for semantic fidelity and diverse lay-style generation in MLLG task. To address these limitations, we propose Magical, an asymmetric LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical employs a shared matrix A for abstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To preserve semantic fidelity during the lay language generation process, Magical introduces a Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix A. Furthermore, to better adapt to diverse lay-style generation, Magical incorporates the Recommendation-guided Switch, an externally interface to prompt the LLM to switch between different matrices B. Experimental results on three real-world lay language generation datasets demonstrate that Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also reducing trainable parameters by 31.66%.  \n",
      "   **Link**: http://arxiv.org/abs/2508.08730v1  \n",
      "\n",
      "8. **Title**: Adaptive Personalized Conversational Information Retrieval  \n",
      "   **Authors**: Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu Huang, Jian-Yun Nie  \n",
      "   **Abstract**: Personalized conversational information retrieval (CIR) systems aim to satisfy users' complex information needs through multi-turn interactions by considering user profiles. However, not all search queries require personalization. The challenge lies in appropriately incorporating personalization elements into search when needed. Most existing studies implicitly incorporate users' personal information and conversational context using large language models without distinguishing the specific requirements for each query turn. Such a one-size-fits-all personalization strategy might lead to sub-optimal results. In this paper, we propose an adaptive personalization method, in which we first identify the required personalization level for a query and integrate personalized queries with other query reformulations to produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to assign fusion weights dynamically to different reformulated queries, depending on the required personalization level. The proposed adaptive personalized conversational information retrieval framework APCIR is evaluated on two TREC iKAT datasets. The results confirm the effectiveness of adaptive personalization of\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "\n",
      "=====\n",
      "## HUMAN FEEDBACK: Provide feedback on the Final Result and Agent's actions.\n",
      "Please follow these guidelines:\n",
      " - If you are happy with the result, simply hit Enter without typing anything.\n",
      " - Otherwise, provide specific improvement requests.\n",
      " - You can provide multiple rounds of feedback until satisfied.\n",
      "=====\n",
      "\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Completion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">3f4cd04e-f3a2-48ba-88ba-842517778a84</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Senior Researcher</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32m3f4cd04e-f3a2-48ba-88ba-842517778a84\u001b[0m                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mSenior Researcher\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– Agent Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Frontend &amp; AI Engineer</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Compile the results into a detailed report in a HTML file.</span>                                               <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35mâ•­â”€\u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35m ğŸ¤– Agent Started \u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35mâ”€â•®\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Frontend & AI Engineer\u001b[0m                                                                           \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mCompile the results into a detailed report in a HTML file.\u001b[0m                                               \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
       "\u001b[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Agent Final Answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Senior Frontend &amp; AI Engineer</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```html</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;!DOCTYPE html&gt;</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;html lang=\"en\"&gt;</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;head&gt;</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;meta charset=\"UTF-8\"&gt;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;title&gt;Top 10 AI Research Papers - 2025-08-12&lt;/title&gt;</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;style&gt;</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        body {</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-family: Arial, sans-serif;</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            line-height: 1.6;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            max-width: 1200px;</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin: 0 auto;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            padding: 20px;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: #333;</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        h1 {</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: #2c3e50;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            text-align: center;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 30px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        .paper {</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            background-color: #f9f9f9;</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            border-radius: 8px;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            padding: 20px;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 20px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            box-shadow: 0 2px 5px rgba(0,0,0,0.1);</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        .paper-title {</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: #3498db;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-size: 1.2em;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 10px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        .paper-title a {</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            text-decoration: none;</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: inherit;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        .paper-title a:hover {</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            text-decoration: underline;</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        .authors {</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: #7f8c8d;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-style: italic;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 10px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        .abstract {</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 5px;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/style&gt;</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;/head&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;body&gt;</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h1&gt;Top 10 AI Research Papers published on 2025-08-12&lt;/h1&gt;</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09389v1\" target=\"_blank\"&gt;ProMode: A Speech</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Prosody Model Conditioned on Acoustic and Textual Inputs&lt;/a&gt;&lt;/h2&gt;</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan&lt;/div&gt;</span>            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;Prosody conveys rich emotional and semantic information of the speech signal as</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">well as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">F0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">features and time-aligned textual content, both are partially masked, and obtains a fixed-length latent </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and unmasked textual content.&lt;/div&gt;</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09378v1\" target=\"_blank\"&gt;APIO: Automatic </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification&lt;/a&gt;&lt;/h2&gt;</span>            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja&lt;/div&gt;</span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;Recent advancements in large language models (LLMs) have enabled a wide range </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. In </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(GEC) and Text Simplification, without relying on manually specified seed prompts.&lt;/div&gt;</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09349v1\" target=\"_blank\"&gt;The Human-AI </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains&lt;/a&gt;&lt;/h2&gt;</span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Cathy Speed, Ahmed A. Metwally&lt;/div&gt;</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">phases: retrospective replication, prospective comparison, and applied deployment in two applied domains. The</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">framework offers a flexible, scalable approach for generating high-quality, context-sensitive </span>                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">consensus.&lt;/div&gt;</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09303v1\" target=\"_blank\"&gt;ParallelSearch: </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning&lt;/a&gt;&lt;/h2&gt;</span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju&lt;/div&gt;</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;We propose ParallelSearch, a novel reinforcement learning framework that </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">search operations concurrently. Our approach introduces dedicated reward functions that incentivize the </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">identification of independent query components while preserving answer accuracy through jointly considering </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">correctness, query decomposition quality, and parallel execution benefits.&lt;/div&gt;</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\"&gt;Feedback-Driven </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Tool-Use Improvements in Large Language Models via Automated Build Environments&lt;/a&gt;&lt;/h2&gt;</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Xiaoran Fan, Qi Zhang, Xuanjing Huang, Jiecao Chen&lt;/div&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;We propose an automated environment construction pipeline, incorporating </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">scenario decomposition, document generation, function integration, complexity scaling, and localized </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">deployment. This enables the creation of high-quality training environments that provide detailed and </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mechanism that evaluates both the precision of tool use and the completeness of task execution.&lt;/div&gt;</span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\"&gt;Can AI Keep a </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs&lt;/a&gt;&lt;/h2&gt;</span>                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Aayush Gupta&lt;/div&gt;</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;We present Contextual Integrity Verification (CIV), an inference-time security </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">architecture that attaches cryptographically signed provenance labels to every token and enforces a </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">source-trust lattice inside the transformer via a pre-softmax hard attention mask. CIV provides </span>               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">higher-trust representations.&lt;/div&gt;</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\"&gt;Magical: Medical </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation&lt;/a&gt;&lt;/h2&gt;</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma&lt;/div&gt;</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;We propose Magical, an asymmetric LoRA architecture tailored for Medical Lay </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Language Generation (MLLG) under heterogeneous data scenarios. Magical employs a shared matrix A for </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">abstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">preserve semantic fidelity during the lay language generation process, Magical introduces a Semantic </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Invariance Constraint to mitigate semantic subspace shifts on matrix A.&lt;/div&gt;</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\"&gt;Adaptive </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Personalized Conversational Information Retrieval&lt;/a&gt;&lt;/h2&gt;</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Huang, Jian-Yun Nie&lt;/div&gt;</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;We propose an adaptive personalization method, in which we first identify the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">required personalization level for a query and integrate personalized queries with other query reformulations</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">assign fusion weights dynamically to different reformulated queries, depending on the required </span>                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">personalization level.&lt;/div&gt;</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\"&gt;Revisiting </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Knowledge Graph Completion Evaluation: A Realistic Benchmark and Enhanced Metrics&lt;/a&gt;&lt;/h2&gt;</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Zaiqiao Meng, Hongyu Ren, Jie Zhang, Richard McCreadie&lt;/div&gt;</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;Knowledge Graph Completion (KGC) evaluation often relies on biased datasets and</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unrealistic evaluation protocols that favor simple statistical patterns over genuine reasoning. We introduce </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a rigorous benchmarking methodology and propose novel metrics that address three key limitations: head/tail </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">entity imbalance, triple redundancy, and the separation of inference from memorization. Our benchmark derived</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from Wikidata rebalancing the predictive tasks proportionally to real-world data characteristics.&lt;/div&gt;</span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\"&gt;Helmholtz </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Decomposition for Interpretable Analysis of Neural Network Dynamics&lt;/a&gt;&lt;/h2&gt;</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"authors\"&gt;Yuki Asano, Jorge A. Hobert, Kim Stachenfeld, Dhruv Nandam&lt;/div&gt;</span>                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;div class=\"abstract\"&gt;We introduce a novel application of Helmholtz decomposition to analyze neural </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">network dynamics by separating the network's vector field into curl-free (gradient) and divergence-free </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(solenoidal) components. This decomposition reveals that the gradient component dominates early learning </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">phases by reducing the training loss, while the solenoidal component becomes prominent in later phases and is</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">correlated with robustness metrics. We demonstrate this approach's utility across vision and language </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tasks.&lt;/div&gt;</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;/body&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;/html&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m âœ… Agent Final Answer \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mSenior Frontend & AI Engineer\u001b[0m                                                                           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m```html\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m<!DOCTYPE html>\u001b[0m                                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m<html lang=\"en\">\u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m<head>\u001b[0m                                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <meta charset=\"UTF-8\">\u001b[0m                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\u001b[0m                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <title>Top 10 AI Research Papers - 2025-08-12</title>\u001b[0m                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <style>\u001b[0m                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        body {\u001b[0m                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            font-family: Arial, sans-serif;\u001b[0m                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            line-height: 1.6;\u001b[0m                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            max-width: 1200px;\u001b[0m                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            margin: 0 auto;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            padding: 20px;\u001b[0m                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            color: #333;\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        h1 {\u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            color: #2c3e50;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            text-align: center;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            margin-bottom: 30px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        .paper {\u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            background-color: #f9f9f9;\u001b[0m                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            border-radius: 8px;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            padding: 20px;\u001b[0m                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            margin-bottom: 20px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\u001b[0m                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        .paper-title {\u001b[0m                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            color: #3498db;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            font-size: 1.2em;\u001b[0m                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            margin-bottom: 10px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        .paper-title a {\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            text-decoration: none;\u001b[0m                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            color: inherit;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        .paper-title a:hover {\u001b[0m                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            text-decoration: underline;\u001b[0m                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        .authors {\u001b[0m                                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            color: #7f8c8d;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            font-style: italic;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            margin-bottom: 10px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        .abstract {\u001b[0m                                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m            margin-bottom: 5px;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </style>\u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m</head>\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m<body>\u001b[0m                                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <h1>Top 10 AI Research Papers published on 2025-08-12</h1>\u001b[0m                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    \u001b[0m                                                                                                           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09389v1\" target=\"_blank\">ProMode: A Speech\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mProsody Model Conditioned on Acoustic and Textual Inputs</a></h2>\u001b[0m                                              \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan</div>\u001b[0m            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">Prosody conveys rich emotional and semantic information of the speech signal as\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mwell as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mF0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mfeatures and time-aligned textual content, both are partially masked, and obtains a fixed-length latent \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mprosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mand unmasked textual content.</div>\u001b[0m                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09378v1\" target=\"_blank\">APIO: Automatic \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mPrompt Induction and Optimization for Grammatical Error Correction and Text Simplification</a></h2>\u001b[0m            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja</div>\u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">Recent advancements in large language models (LLMs) have enabled a wide range \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mof natural language processing (NLP) tasks to be performed through simple prompt-based interactions. In \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msettings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mmethods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msimple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m(GEC) and Text Simplification, without relying on manually specified seed prompts.</div>\u001b[0m                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09349v1\" target=\"_blank\">The Human-AI \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mHybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains</a></h2>\u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Cathy Speed, Ahmed A. Metwally</div>\u001b[0m                                              \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mframework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mPro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mphases: retrospective replication, prospective comparison, and applied deployment in two applied domains. The\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mframework offers a flexible, scalable approach for generating high-quality, context-sensitive \u001b[0m                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mconsensus.</div>\u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09303v1\" target=\"_blank\">ParallelSearch: \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mTrain your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning</a></h2>\u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju</div>\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">We propose ParallelSearch, a novel reinforcement learning framework that \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mempowers large language models (LLMs) to recognize parallelizable query structures and execute multiple \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msearch operations concurrently. Our approach introduces dedicated reward functions that incentivize the \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92midentification of independent query components while preserving answer accuracy through jointly considering \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcorrectness, query decomposition quality, and parallel execution benefits.</div>\u001b[0m                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\">Feedback-Driven \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mTool-Use Improvements in Large Language Models via Automated Build Environments</a></h2>\u001b[0m                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mXiaoran Fan, Qi Zhang, Xuanjing Huang, Jiecao Chen</div>\u001b[0m                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">We propose an automated environment construction pipeline, incorporating \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mscenario decomposition, document generation, function integration, complexity scaling, and localized \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdeployment. This enables the creation of high-quality training environments that provide detailed and \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mmeasurable feedback without relying on external tools. Additionally, we introduce a verifiable reward \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mmechanism that evaluates both the precision of tool use and the completeness of task execution.</div>\u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\">Can AI Keep a \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mSecret? Contextual Integrity Verification: A Provable Security Architecture for LLMs</a></h2>\u001b[0m                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Aayush Gupta</div>\u001b[0m                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">We present Contextual Integrity Verification (CIV), an inference-time security \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92marchitecture that attaches cryptographically signed provenance labels to every token and enforces a \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92msource-trust lattice inside the transformer via a pre-softmax hard attention mask. CIV provides \u001b[0m               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mdeterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mhigher-trust representations.</div>\u001b[0m                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\">Magical: Medical \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mLay Language Generation via Semantic Invariance and Layperson-tailored Adaptation</a></h2>\u001b[0m                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma</div>\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">We propose Magical, an asymmetric LoRA architecture tailored for Medical Lay \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mLanguage Generation (MLLG) under heterogeneous data scenarios. Magical employs a shared matrix A for \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mabstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpreserve semantic fidelity during the lay language generation process, Magical introduces a Semantic \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mInvariance Constraint to mitigate semantic subspace shifts on matrix A.</div>\u001b[0m                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\">Adaptive \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mPersonalized Conversational Information Retrieval</a></h2>\u001b[0m                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mHuang, Jian-Yun Nie</div>\u001b[0m                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">We propose an adaptive personalization method, in which we first identify the \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mrequired personalization level for a query and integrate personalized queries with other query reformulations\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mto produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92massign fusion weights dynamically to different reformulated queries, depending on the required \u001b[0m                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mpersonalization level.</div>\u001b[0m                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\">Revisiting \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mKnowledge Graph Completion Evaluation: A Realistic Benchmark and Enhanced Metrics</a></h2>\u001b[0m                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Zaiqiao Meng, Hongyu Ren, Jie Zhang, Richard McCreadie</div>\u001b[0m                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">Knowledge Graph Completion (KGC) evaluation often relies on biased datasets and\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92munrealistic evaluation protocols that favor simple statistical patterns over genuine reasoning. We introduce \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92ma rigorous benchmarking methodology and propose novel metrics that address three key limitations: head/tail \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mentity imbalance, triple redundancy, and the separation of inference from memorization. Our benchmark derived\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mfrom Wikidata rebalancing the predictive tasks proportionally to real-world data characteristics.</div>\u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\">Helmholtz \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mDecomposition for Interpretable Analysis of Neural Network Dynamics</a></h2>\u001b[0m                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"authors\">Yuki Asano, Jorge A. Hobert, Kim Stachenfeld, Dhruv Nandam</div>\u001b[0m                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m        <div class=\"abstract\">We introduce a novel application of Helmholtz decomposition to analyze neural \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mnetwork dynamics by separating the network's vector field into curl-free (gradient) and divergence-free \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m(solenoidal) components. This decomposition reveals that the gradient component dominates early learning \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mphases by reducing the training loss, while the solenoidal component becomes prominent in later phases and is\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mcorrelated with robustness metrics. We demonstrate this approach's utility across vision and language \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92mtasks.</div>\u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m</body>\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m</html>\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m ## Final Result:\u001b[00m \u001b[92m```html\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Top 10 AI Research Papers - 2025-08-12</title>\n",
      "    <style>\n",
      "        body {\n",
      "            font-family: Arial, sans-serif;\n",
      "            line-height: 1.6;\n",
      "            max-width: 1200px;\n",
      "            margin: 0 auto;\n",
      "            padding: 20px;\n",
      "            color: #333;\n",
      "        }\n",
      "        h1 {\n",
      "            color: #2c3e50;\n",
      "            text-align: center;\n",
      "            margin-bottom: 30px;\n",
      "        }\n",
      "        .paper {\n",
      "            background-color: #f9f9f9;\n",
      "            border-radius: 8px;\n",
      "            padding: 20px;\n",
      "            margin-bottom: 20px;\n",
      "            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
      "        }\n",
      "        .paper-title {\n",
      "            color: #3498db;\n",
      "            font-size: 1.2em;\n",
      "            margin-bottom: 10px;\n",
      "        }\n",
      "        .paper-title a {\n",
      "            text-decoration: none;\n",
      "            color: inherit;\n",
      "        }\n",
      "        .paper-title a:hover {\n",
      "            text-decoration: underline;\n",
      "        }\n",
      "        .authors {\n",
      "            color: #7f8c8d;\n",
      "            font-style: italic;\n",
      "            margin-bottom: 10px;\n",
      "        }\n",
      "        .abstract {\n",
      "            margin-bottom: 5px;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <h1>Top 10 AI Research Papers published on 2025-08-12</h1>\n",
      "    \n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09389v1\" target=\"_blank\">ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs</a></h2>\n",
      "        <div class=\"authors\">Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan</div>\n",
      "        <div class=\"abstract\">Prosody conveys rich emotional and semantic information of the speech signal as well as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as F0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic features and time-aligned textual content, both are partially masked, and obtains a fixed-length latent prosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input and unmasked textual content.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09378v1\" target=\"_blank\">APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification</a></h2>\n",
      "        <div class=\"authors\">Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja</div>\n",
      "        <div class=\"abstract\">Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09349v1\" target=\"_blank\">The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains</a></h2>\n",
      "        <div class=\"authors\">Cathy Speed, Ahmed A. Metwally</div>\n",
      "        <div class=\"abstract\">This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three phases: retrospective replication, prospective comparison, and applied deployment in two applied domains. The framework offers a flexible, scalable approach for generating high-quality, context-sensitive consensus.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09303v1\" target=\"_blank\">ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning</a></h2>\n",
      "        <div class=\"authors\">Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju</div>\n",
      "        <div class=\"abstract\">We propose ParallelSearch, a novel reinforcement learning framework that empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple search operations concurrently. Our approach introduces dedicated reward functions that incentivize the identification of independent query components while preserving answer accuracy through jointly considering correctness, query decomposition quality, and parallel execution benefits.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\">Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments</a></h2>\n",
      "        <div class=\"authors\">Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, Xiaoran Fan, Qi Zhang, Xuanjing Huang, Jiecao Chen</div>\n",
      "        <div class=\"abstract\">We propose an automated environment construction pipeline, incorporating scenario decomposition, document generation, function integration, complexity scaling, and localized deployment. This enables the creation of high-quality training environments that provide detailed and measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward mechanism that evaluates both the precision of tool use and the completeness of task execution.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\">Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs</a></h2>\n",
      "        <div class=\"authors\">Aayush Gupta</div>\n",
      "        <div class=\"abstract\">We present Contextual Integrity Verification (CIV), an inference-time security architecture that attaches cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the transformer via a pre-softmax hard attention mask. CIV provides deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence higher-trust representations.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\">Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation</a></h2>\n",
      "        <div class=\"authors\">Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma</div>\n",
      "        <div class=\"abstract\">We propose Magical, an asymmetric LoRA architecture tailored for Medical Lay Language Generation (MLLG) under heterogeneous data scenarios. Magical employs a shared matrix A for abstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To preserve semantic fidelity during the lay language generation process, Magical introduces a Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix A.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\">Adaptive Personalized Conversational Information Retrieval</a></h2>\n",
      "        <div class=\"authors\">Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu Huang, Jian-Yun Nie</div>\n",
      "        <div class=\"abstract\">We propose an adaptive personalization method, in which we first identify the required personalization level for a query and integrate personalized queries with other query reformulations to produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to assign fusion weights dynamically to different reformulated queries, depending on the required personalization level.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\">Revisiting Knowledge Graph Completion Evaluation: A Realistic Benchmark and Enhanced Metrics</a></h2>\n",
      "        <div class=\"authors\">Zaiqiao Meng, Hongyu Ren, Jie Zhang, Richard McCreadie</div>\n",
      "        <div class=\"abstract\">Knowledge Graph Completion (KGC) evaluation often relies on biased datasets and unrealistic evaluation protocols that favor simple statistical patterns over genuine reasoning. We introduce a rigorous benchmarking methodology and propose novel metrics that address three key limitations: head/tail entity imbalance, triple redundancy, and the separation of inference from memorization. Our benchmark derived from Wikidata rebalancing the predictive tasks proportionally to real-world data characteristics.</div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"paper\">\n",
      "        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\">Helmholtz Decomposition for Interpretable Analysis of Neural Network Dynamics</a></h2>\n",
      "        <div class=\"authors\">Yuki Asano, Jorge A. Hobert, Kim Stachenfeld, Dhruv Nandam</div>\n",
      "        <div class=\"abstract\">We introduce a novel application of Helmholtz decomposition to analyze neural network dynamics by separating the network's vector field into curl-free (gradient) and divergence-free (solenoidal) components. This decomposition reveals that the gradient component dominates early learning phases by reducing the training loss, while the solenoidal component becomes prominent in later phases and is correlated with robustness metrics. We demonstrate this approach's utility across vision and language tasks.</div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "```\u001b[00m\n",
      "\u001b[1m\u001b[93m \n",
      "\n",
      "=====\n",
      "## HUMAN FEEDBACK: Provide feedback on the Final Result and Agent's actions.\n",
      "Please follow these guidelines:\n",
      " - If you are happy with the result, simply hit Enter without typing anything.\n",
      " - Otherwise, provide specific improvement requests.\n",
      " - You can provide multiple rounds of feedback until satisfied.\n",
      "=====\n",
      "\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Completion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">daeea218-f98f-4172-ab69-81bce118f542</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Senior Frontend &amp; AI Engineer</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mdaeea218-f98f-4172-ab69-81bce118f542\u001b[0m                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mSenior Frontend & AI Engineer\u001b[0m                                                                           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Completion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Crew Execution Completed</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">crew</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008000; text-decoration-color: #008000\">0c7ddc43-37b2-40a3-b501-93d68c8a51fb</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: ```html</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;!DOCTYPE html&gt;</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;html lang=\"en\"&gt;</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;head&gt;</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;meta charset=\"UTF-8\"&gt;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;title&gt;Top 10 AI Research Papers - 2025-08-12&lt;/title&gt;</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;style&gt;</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        body {</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            font-family: Arial, sans-serif;</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            line-height: 1.6;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            max-width: 1200px;</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            margin: 0 auto;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            padding: 20px;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            color: #333;</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        h1 {</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            color: #2c3e50;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            text-align: center;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            margin-bottom: 30px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        .paper {</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            background-color: #f9f9f9;</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            border-radius: 8px;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            padding: 20px;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            margin-bottom: 20px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            box-shadow: 0 2px 5px rgba(0,0,0,0.1);</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        .paper-title {</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            color: #3498db;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            font-size: 1.2em;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            margin-bottom: 10px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        .paper-title a {</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            text-decoration: none;</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            color: inherit;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        .paper-title a:hover {</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            text-decoration: underline;</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        .authors {</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            color: #7f8c8d;</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            font-style: italic;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            margin-bottom: 10px;</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        .abstract {</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">            margin-bottom: 5px;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/style&gt;</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;/head&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;body&gt;</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;h1&gt;Top 10 AI Research Papers published on 2025-08-12&lt;/h1&gt;</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    </span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09389v1\" target=\"_blank\"&gt;ProMode: A Speech</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Prosody Model Conditioned on Acoustic and Textual Inputs&lt;/a&gt;&lt;/h2&gt;</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan&lt;/div&gt;</span>            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;Prosody conveys rich emotional and semantic information of the speech signal as</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">well as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">F0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">features and time-aligned textual content, both are partially masked, and obtains a fixed-length latent </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">prosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">and unmasked textual content.&lt;/div&gt;</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09378v1\" target=\"_blank\"&gt;APIO: Automatic </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification&lt;/a&gt;&lt;/h2&gt;</span>            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja&lt;/div&gt;</span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;Recent advancements in large language models (LLMs) have enabled a wide range </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. In </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">(GEC) and Text Simplification, without relying on manually specified seed prompts.&lt;/div&gt;</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09349v1\" target=\"_blank\"&gt;The Human-AI </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains&lt;/a&gt;&lt;/h2&gt;</span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Cathy Speed, Ahmed A. Metwally&lt;/div&gt;</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">phases: retrospective replication, prospective comparison, and applied deployment in two applied domains. The</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">framework offers a flexible, scalable approach for generating high-quality, context-sensitive </span>                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">consensus.&lt;/div&gt;</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09303v1\" target=\"_blank\"&gt;ParallelSearch: </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning&lt;/a&gt;&lt;/h2&gt;</span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju&lt;/div&gt;</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;We propose ParallelSearch, a novel reinforcement learning framework that </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">search operations concurrently. Our approach introduces dedicated reward functions that incentivize the </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">identification of independent query components while preserving answer accuracy through jointly considering </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">correctness, query decomposition quality, and parallel execution benefits.&lt;/div&gt;</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\"&gt;Feedback-Driven </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool-Use Improvements in Large Language Models via Automated Build Environments&lt;/a&gt;&lt;/h2&gt;</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Xiaoran Fan, Qi Zhang, Xuanjing Huang, Jiecao Chen&lt;/div&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;We propose an automated environment construction pipeline, incorporating </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">scenario decomposition, document generation, function integration, complexity scaling, and localized </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">deployment. This enables the creation of high-quality training environments that provide detailed and </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">mechanism that evaluates both the precision of tool use and the completeness of task execution.&lt;/div&gt;</span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\"&gt;Can AI Keep a </span>     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs&lt;/a&gt;&lt;/h2&gt;</span>                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Aayush Gupta&lt;/div&gt;</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;We present Contextual Integrity Verification (CIV), an inference-time security </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">architecture that attaches cryptographically signed provenance labels to every token and enforces a </span>           <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">source-trust lattice inside the transformer via a pre-softmax hard attention mask. CIV provides </span>               <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">higher-trust representations.&lt;/div&gt;</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\"&gt;Magical: Medical </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation&lt;/a&gt;&lt;/h2&gt;</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma&lt;/div&gt;</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;We propose Magical, an asymmetric LoRA architecture tailored for Medical Lay </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Language Generation (MLLG) under heterogeneous data scenarios. Magical employs a shared matrix A for </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">abstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">preserve semantic fidelity during the lay language generation process, Magical introduces a Semantic </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Invariance Constraint to mitigate semantic subspace shifts on matrix A.&lt;/div&gt;</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\"&gt;Adaptive </span>          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Personalized Conversational Information Retrieval&lt;/a&gt;&lt;/h2&gt;</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu </span>    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Huang, Jian-Yun Nie&lt;/div&gt;</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;We propose an adaptive personalization method, in which we first identify the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">required personalization level for a query and integrate personalized queries with other query reformulations</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">to produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">assign fusion weights dynamically to different reformulated queries, depending on the required </span>                <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">personalization level.&lt;/div&gt;</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\"&gt;Revisiting </span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Knowledge Graph Completion Evaluation: A Realistic Benchmark and Enhanced Metrics&lt;/a&gt;&lt;/h2&gt;</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Zaiqiao Meng, Hongyu Ren, Jie Zhang, Richard McCreadie&lt;/div&gt;</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;Knowledge Graph Completion (KGC) evaluation often relies on biased datasets and</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">unrealistic evaluation protocols that favor simple statistical patterns over genuine reasoning. We introduce </span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">a rigorous benchmarking methodology and propose novel metrics that address three key limitations: head/tail </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">entity imbalance, triple redundancy, and the separation of inference from memorization. Our benchmark derived</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">from Wikidata rebalancing the predictive tasks proportionally to real-world data characteristics.&lt;/div&gt;</span>        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;div class=\"paper\"&gt;</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;h2 class=\"paper-title\"&gt;&lt;a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\"&gt;Helmholtz </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Decomposition for Interpretable Analysis of Neural Network Dynamics&lt;/a&gt;&lt;/h2&gt;</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"authors\"&gt;Yuki Asano, Jorge A. Hobert, Kim Stachenfeld, Dhruv Nandam&lt;/div&gt;</span>                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        &lt;div class=\"abstract\"&gt;We introduce a novel application of Helmholtz decomposition to analyze neural </span>   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">network dynamics by separating the network's vector field into curl-free (gradient) and divergence-free </span>       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">(solenoidal) components. This decomposition reveals that the gradient component dominates early learning </span>      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">phases by reducing the training loss, while the solenoidal component becomes prominent in later phases and is</span>  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">correlated with robustness metrics. We demonstrate this approach's utility across vision and language </span>         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">tasks.&lt;/div&gt;</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    &lt;/div&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;/body&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">&lt;/html&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Crew Completion \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[1;32mCrew Execution Completed\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mcrew\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mID: \u001b[0m\u001b[32m0c7ddc43-37b2-40a3-b501-93d68c8a51fb\u001b[0m                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mFinal Output: ```html\u001b[0m                                                                                          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m<!DOCTYPE html>\u001b[0m                                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m<html lang=\"en\">\u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m<head>\u001b[0m                                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <meta charset=\"UTF-8\">\u001b[0m                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\u001b[0m                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <title>Top 10 AI Research Papers - 2025-08-12</title>\u001b[0m                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <style>\u001b[0m                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        body {\u001b[0m                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            font-family: Arial, sans-serif;\u001b[0m                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            line-height: 1.6;\u001b[0m                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            max-width: 1200px;\u001b[0m                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            margin: 0 auto;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            padding: 20px;\u001b[0m                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            color: #333;\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        h1 {\u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            color: #2c3e50;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            text-align: center;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            margin-bottom: 30px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        .paper {\u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            background-color: #f9f9f9;\u001b[0m                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            border-radius: 8px;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            padding: 20px;\u001b[0m                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            margin-bottom: 20px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            box-shadow: 0 2px 5px rgba(0,0,0,0.1);\u001b[0m                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        .paper-title {\u001b[0m                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            color: #3498db;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            font-size: 1.2em;\u001b[0m                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            margin-bottom: 10px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        .paper-title a {\u001b[0m                                                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            text-decoration: none;\u001b[0m                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            color: inherit;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        .paper-title a:hover {\u001b[0m                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            text-decoration: underline;\u001b[0m                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        .authors {\u001b[0m                                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            color: #7f8c8d;\u001b[0m                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            font-style: italic;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            margin-bottom: 10px;\u001b[0m                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        .abstract {\u001b[0m                                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m            margin-bottom: 5px;\u001b[0m                                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        }\u001b[0m                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </style>\u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m</head>\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m<body>\u001b[0m                                                                                                         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <h1>Top 10 AI Research Papers published on 2025-08-12</h1>\u001b[0m                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    \u001b[0m                                                                                                           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09389v1\" target=\"_blank\">ProMode: A Speech\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mProsody Model Conditioned on Acoustic and Textual Inputs</a></h2>\u001b[0m                                              \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Eray Eren, Qingju Liu, Hyeongwoo Kim, Pablo Garrido, Abeer Alwan</div>\u001b[0m            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">Prosody conveys rich emotional and semantic information of the speech signal as\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mwell as individual idiosyncrasies. We propose a stand-alone model that maps text-to-prosodic features such as\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mF0 and energy and can be used in downstream tasks such as TTS. The ProMode encoder takes as input acoustic \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mfeatures and time-aligned textual content, both are partially masked, and obtains a fixed-length latent \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mprosodic embedding. The decoder predicts acoustics in the masked region using both the encoded prosody input \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mand unmasked textual content.</div>\u001b[0m                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09378v1\" target=\"_blank\">APIO: Automatic \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mPrompt Induction and Optimization for Grammatical Error Correction and Text Simplification</a></h2>\u001b[0m            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja</div>\u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">Recent advancements in large language models (LLMs) have enabled a wide range \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mof natural language processing (NLP) tasks to be performed through simple prompt-based interactions. In \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37msettings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mmethods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37msimple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m(GEC) and Text Simplification, without relying on manually specified seed prompts.</div>\u001b[0m                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09349v1\" target=\"_blank\">The Human-AI \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mHybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains</a></h2>\u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Cathy Speed, Ahmed A. Metwally</div>\u001b[0m                                              \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mframework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mPro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mphases: retrospective replication, prospective comparison, and applied deployment in two applied domains. The\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mframework offers a flexible, scalable approach for generating high-quality, context-sensitive \u001b[0m                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mconsensus.</div>\u001b[0m                                                                                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09303v1\" target=\"_blank\">ParallelSearch: \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mTrain your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning</a></h2>\u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Shu Zhao, Tan Yu, Anbang Xu, Japinder Singh, Aaditya Shukla, Rama Akkiraju</div>\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">We propose ParallelSearch, a novel reinforcement learning framework that \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mempowers large language models (LLMs) to recognize parallelizable query structures and execute multiple \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37msearch operations concurrently. Our approach introduces dedicated reward functions that incentivize the \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37midentification of independent query components while preserving answer accuracy through jointly considering \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mcorrectness, query decomposition quality, and parallel execution benefits.</div>\u001b[0m                               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\">Feedback-Driven \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mTool-Use Improvements in Large Language Models via Automated Build Environments</a></h2>\u001b[0m                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng Xi, \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mXiaoran Fan, Qi Zhang, Xuanjing Huang, Jiecao Chen</div>\u001b[0m                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">We propose an automated environment construction pipeline, incorporating \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mscenario decomposition, document generation, function integration, complexity scaling, and localized \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mdeployment. This enables the creation of high-quality training environments that provide detailed and \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mmeasurable feedback without relying on external tools. Additionally, we introduce a verifiable reward \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mmechanism that evaluates both the precision of tool use and the completeness of task execution.</div>\u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\">Can AI Keep a \u001b[0m     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mSecret? Contextual Integrity Verification: A Provable Security Architecture for LLMs</a></h2>\u001b[0m                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Aayush Gupta</div>\u001b[0m                                                                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">We present Contextual Integrity Verification (CIV), an inference-time security \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37marchitecture that attaches cryptographically signed provenance labels to every token and enforces a \u001b[0m           \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37msource-trust lattice inside the transformer via a pre-softmax hard attention mask. CIV provides \u001b[0m               \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mdeterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mhigher-trust representations.</div>\u001b[0m                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\">Magical: Medical \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mLay Language Generation via Semantic Invariance and Layperson-tailored Adaptation</a></h2>\u001b[0m                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Weibin Liao, Tianlong Wang, Yinghao Zhu, Yasha Wang, Junyi Gao, Liantao Ma</div>\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">We propose Magical, an asymmetric LoRA architecture tailored for Medical Lay \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mLanguage Generation (MLLG) under heterogeneous data scenarios. Magical employs a shared matrix A for \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mabstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mpreserve semantic fidelity during the lay language generation process, Magical introduces a Semantic \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mInvariance Constraint to mitigate semantic subspace shifts on matrix A.</div>\u001b[0m                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08730v1\" target=\"_blank\">Adaptive \u001b[0m          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mPersonalized Conversational Information Retrieval</a></h2>\u001b[0m                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Fengran Mo, Yuchen Hui, Yuxing Tian, Zhaoxuan Tan, Chuan Meng, Zhan Su, Kaiyu \u001b[0m    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mHuang, Jian-Yun Nie</div>\u001b[0m                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">We propose an adaptive personalization method, in which we first identify the \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mrequired personalization level for a query and integrate personalized queries with other query reformulations\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mto produce various enhanced queries. Then, we design a personalization-aware ranking fusion approach to \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37massign fusion weights dynamically to different reformulated queries, depending on the required \u001b[0m                \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mpersonalization level.</div>\u001b[0m                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.08791v1\" target=\"_blank\">Revisiting \u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mKnowledge Graph Completion Evaluation: A Realistic Benchmark and Enhanced Metrics</a></h2>\u001b[0m                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Zaiqiao Meng, Hongyu Ren, Jie Zhang, Richard McCreadie</div>\u001b[0m                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">Knowledge Graph Completion (KGC) evaluation often relies on biased datasets and\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37munrealistic evaluation protocols that favor simple statistical patterns over genuine reasoning. We introduce \u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37ma rigorous benchmarking methodology and propose novel metrics that address three key limitations: head/tail \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mentity imbalance, triple redundancy, and the separation of inference from memorization. Our benchmark derived\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mfrom Wikidata rebalancing the predictive tasks proportionally to real-world data characteristics.</div>\u001b[0m        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    <div class=\"paper\">\u001b[0m                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <h2 class=\"paper-title\"><a href=\"http://arxiv.org/abs/2508.09288v1\" target=\"_blank\">Helmholtz \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mDecomposition for Interpretable Analysis of Neural Network Dynamics</a></h2>\u001b[0m                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"authors\">Yuki Asano, Jorge A. Hobert, Kim Stachenfeld, Dhruv Nandam</div>\u001b[0m                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m        <div class=\"abstract\">We introduce a novel application of Helmholtz decomposition to analyze neural \u001b[0m   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mnetwork dynamics by separating the network's vector field into curl-free (gradient) and divergence-free \u001b[0m       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m(solenoidal) components. This decomposition reveals that the gradient component dominates early learning \u001b[0m      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mphases by reducing the training loss, while the solenoidal component becomes prominent in later phases and is\u001b[0m  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mcorrelated with robustness metrics. We demonstrate this approach's utility across vision and language \u001b[0m         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37mtasks.</div>\u001b[0m                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m    </div>\u001b[0m                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m</body>\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m</html>\u001b[0m                                                                                                        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 7: Running the Crew and Giving Feedback on its results. \n",
    "crew_inputs = {\n",
    "    \"date\" : \"2025-08-12\"\n",
    "}\n",
    "\n",
    "result = arxiv_research_crew.kickoff(inputs = crew_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchAgentCrewAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
